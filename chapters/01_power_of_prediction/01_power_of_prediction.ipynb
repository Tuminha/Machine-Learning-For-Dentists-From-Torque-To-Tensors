{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 01 - The Power of Prediction in Dentistry\n",
        "\n",
        "> **Book:** Machine Learning For Dentists: From Torque To Tensors\n",
        ">\n",
        "> **Author:** Francisco Teixeira Barbosa\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ What You'll Learn\n",
        "\n",
        "In this notebook, you will:\n",
        "\n",
        "1. Load a simple dataset and see what it looks like\n",
        "2. Understand the difference between **features** (inputs) and **target** (what we predict)\n",
        "3. Split data into **training** and **testing** sets\n",
        "4. Create the simplest possible model: the **baseline**\n",
        "5. Calculate **accuracy** and understand what it means\n",
        "\n",
        "**Time to complete:** ~15 minutes\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Setup: Import Libraries\n",
        "\n",
        "First, we import the tools we'll use. Don't worry if you don't know what each one does yet‚Äîwe'll explain as we go.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Standard libraries for data handling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine learning tools\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Periospot brand colors for consistent styling\n",
        "COLORS = {\n",
        "    'periospot_blue': '#15365a',\n",
        "    'mystic_blue': '#003049',\n",
        "    'periospot_red': '#6c1410',\n",
        "    'crimson_blaze': '#a92a2a',\n",
        "    'vanilla_cream': '#f7f0da',\n",
        "    'black': '#000000',\n",
        "    'white': '#ffffff'\n",
        "}\n",
        "\n",
        "# Set up matplotlib defaults\n",
        "plt.rcParams['font.family'] = 'DejaVu Sans'\n",
        "plt.rcParams['axes.titlesize'] = 16\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "plt.rcParams['xtick.labelsize'] = 10\n",
        "plt.rcParams['ytick.labelsize'] = 10\n",
        "plt.rcParams['figure.facecolor'] = 'white'\n",
        "\n",
        "print(\"‚úÖ Libraries loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìä Step 1: Load the Data\n",
        "\n",
        "For this introductory chapter, we'll use a **toy dataset** (D2). This is intentionally simple so we can focus on the concepts, not the clinical complexity.\n",
        "\n",
        "### Creating a Synthetic Toy Dataset\n",
        "\n",
        "Since we don't have our D2 dataset file yet, we'll create a simple synthetic one. Imagine this represents:\n",
        "\n",
        "- 100 patients\n",
        "- Each patient has a few measurements\n",
        "- We want to predict if they are **high risk** (1) or **low risk** (0)\n",
        "\n",
        "**In a real scenario, you would load this from a CSV file:**\n",
        "```python\n",
        "df = pd.read_csv('../../data/D2_toy_tabular/toy_dental_data.csv')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a simple synthetic dataset for demonstration\n",
        "# In real use, you would load from: ../../data/D2_toy_tabular/\n",
        "\n",
        "np.random.seed(42)  # For reproducibility\n",
        "\n",
        "n_patients = 100\n",
        "\n",
        "# Create features\n",
        "df = pd.DataFrame({\n",
        "    'patient_id': [f'P{i:03d}' for i in range(1, n_patients + 1)],\n",
        "    'age': np.random.normal(55, 12, n_patients).astype(int),\n",
        "    'smoker': np.random.choice([0, 1], n_patients, p=[0.7, 0.3]),\n",
        "    'plaque_score': np.random.uniform(0, 3, n_patients).round(1),\n",
        "    'pocket_depth_avg': np.random.normal(3.5, 1.2, n_patients).round(1)\n",
        "})\n",
        "\n",
        "# Create target: high_risk depends on other features (with some noise)\n",
        "risk_score = (\n",
        "    0.02 * df['age'] + \n",
        "    0.8 * df['smoker'] + \n",
        "    0.3 * df['plaque_score'] + \n",
        "    0.2 * df['pocket_depth_avg'] +\n",
        "    np.random.normal(0, 0.5, n_patients)\n",
        ")\n",
        "df['high_risk'] = (risk_score > np.percentile(risk_score, 70)).astype(int)\n",
        "\n",
        "print(f\"Dataset created with {len(df)} patients\")\n",
        "print(f\"\\nFirst 5 rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Understanding the Data\n",
        "\n",
        "Let's look at what we have:\n",
        "\n",
        "| Column | Description | Type |\n",
        "|--------|-------------|------|\n",
        "| `patient_id` | Unique identifier | ID (not used for prediction) |\n",
        "| `age` | Patient age in years | Feature |\n",
        "| `smoker` | 1 = smoker, 0 = non-smoker | Feature |\n",
        "| `plaque_score` | Plaque index (0-3) | Feature |\n",
        "| `pocket_depth_avg` | Average probing depth (mm) | Feature |\n",
        "| `high_risk` | 1 = high risk, 0 = low risk | **TARGET** |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic information about the dataset\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(f\"\\nWe have {df.shape[0]} patients and {df.shape[1]} columns\")\n",
        "print(\"\\n--- Data Types ---\")\n",
        "print(df.dtypes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"--- Summary Statistics ---\")\n",
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üéØ Step 2: Features vs. Target\n",
        "\n",
        "In machine learning, we distinguish between:\n",
        "\n",
        "- **Features (X):** The information we USE to make predictions\n",
        "- **Target (y):** What we WANT to predict\n",
        "\n",
        "### Clinical Analogy\n",
        "\n",
        "Think of it like this:\n",
        "- **Features:** Patient history, exam findings, measurements\n",
        "- **Target:** The diagnosis or prognosis\n",
        "\n",
        "We use the features to predict the target.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define our features and target\n",
        "\n",
        "# Features: everything except patient_id and the target\n",
        "feature_columns = ['age', 'smoker', 'plaque_score', 'pocket_depth_avg']\n",
        "X = df[feature_columns]\n",
        "\n",
        "# Target: what we want to predict\n",
        "y = df['high_risk']\n",
        "\n",
        "print(\"Features (X):\")\n",
        "print(X.head())\n",
        "print(f\"\\nShape: {X.shape} (100 patients √ó 4 features)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Target (y):\")\n",
        "print(y.head())\n",
        "print(f\"\\nShape: {y.shape} (100 values)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Class Balance: How Many High Risk vs. Low Risk?\n",
        "\n",
        "Before doing any modeling, we should always check the **class balance** ‚Äî how many examples of each class do we have?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check class distribution\n",
        "class_counts = y.value_counts()\n",
        "class_percentages = y.value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "print(f\"  Low Risk (0):  {class_counts[0]} patients ({class_percentages[0]:.1f}%)\")\n",
        "print(f\"  High Risk (1): {class_counts[1]} patients ({class_percentages[1]:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the class distribution\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "bars = ax.bar(\n",
        "    ['Low Risk (0)', 'High Risk (1)'], \n",
        "    class_counts.values,\n",
        "    color=[COLORS['periospot_blue'], COLORS['crimson_blaze']],\n",
        "    edgecolor='black',\n",
        "    linewidth=1.5\n",
        ")\n",
        "\n",
        "# Add count labels on bars\n",
        "for bar, count, pct in zip(bars, class_counts.values, class_percentages.values):\n",
        "    ax.text(\n",
        "        bar.get_x() + bar.get_width()/2, \n",
        "        bar.get_height() + 1,\n",
        "        f'{count} ({pct:.1f}%)',\n",
        "        ha='center', \n",
        "        fontsize=12,\n",
        "        fontweight='bold'\n",
        "    )\n",
        "\n",
        "ax.set_ylabel('Number of Patients', fontsize=12)\n",
        "ax.set_title('Class Distribution: How Many High Risk vs. Low Risk?', fontsize=14, fontweight='bold')\n",
        "ax.set_ylim(0, max(class_counts.values) * 1.15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üí° Key Insight: The Baseline is Already Here!\n",
        "\n",
        "If ~70% of patients are **Low Risk**, then the simplest prediction strategy is:\n",
        "\n",
        "> **\"Predict Low Risk for everyone\"**\n",
        "\n",
        "This gives us ~70% accuracy without looking at ANY features!\n",
        "\n",
        "This is called the **majority class baseline**, and it tells us: **any useful model must beat this.**\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÇÔ∏è Step 3: Train/Test Split\n",
        "\n",
        "Before training a model, we must split our data into:\n",
        "\n",
        "- **Training set:** Data the model learns from\n",
        "- **Test set:** Data we use to evaluate how well the model generalizes\n",
        "\n",
        "### Why Split?\n",
        "\n",
        "Imagine studying for an exam using the exact questions that will be on the test. You'd score perfectly, but would you actually understand the material?\n",
        "\n",
        "The same applies to ML:\n",
        "- Training on ALL data and testing on the SAME data ‚Üí overoptimistic results\n",
        "- We need **unseen data** to know if the model truly learned\n",
        "\n",
        "### Clinical Analogy\n",
        "\n",
        "- **Training set:** Patients you've seen before\n",
        "- **Test set:** New patients walking into your clinic\n",
        "\n",
        "Your skills should work on new patients, not just the ones you memorized.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data: 80% for training, 20% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2,      # 20% goes to test set\n",
        "    random_state=42,    # For reproducibility\n",
        "    stratify=y          # Keep class proportions similar in both sets\n",
        ")\n",
        "\n",
        "print(\"Data split complete!\")\n",
        "print(f\"\\nTraining set: {len(X_train)} patients ({len(X_train)/len(X)*100:.0f}%)\")\n",
        "print(f\"Test set:     {len(X_test)} patients ({len(X_test)/len(X)*100:.0f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify that class proportions are preserved (stratification)\n",
        "print(\"Class distribution in training set:\")\n",
        "print(y_train.value_counts(normalize=True).round(3))\n",
        "\n",
        "print(\"\\nClass distribution in test set:\")\n",
        "print(y_test.value_counts(normalize=True).round(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üé≤ Step 4: The Baseline Model\n",
        "\n",
        "Before using any fancy algorithm, we create a **baseline** ‚Äî the simplest possible prediction.\n",
        "\n",
        "### Why Baseline Matters\n",
        "\n",
        "The baseline tells us:\n",
        "1. **How hard is this problem?** (High baseline = easy problem or imbalanced data)\n",
        "2. **Is our model doing anything useful?** (Must beat baseline to be worthwhile)\n",
        "\n",
        "### Our Baseline Strategy: Majority Class\n",
        "\n",
        "Strategy: **Always predict the most common class in the training data.**\n",
        "\n",
        "If 70% of training patients are Low Risk, we predict Low Risk for everyone.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a baseline model using scikit-learn's DummyClassifier\n",
        "# \"most_frequent\" strategy = always predict the majority class\n",
        "\n",
        "baseline_model = DummyClassifier(strategy='most_frequent', random_state=42)\n",
        "\n",
        "# \"Train\" the baseline (it just learns the most common class)\n",
        "baseline_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Baseline model 'trained'!\")\n",
        "print(f\"\\nThis model will always predict: {baseline_model.classes_[np.argmax(baseline_model.class_prior_)]}\")\n",
        "print(f\"(Because that's the most common class in training data)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the test set\n",
        "y_pred_baseline = baseline_model.predict(X_test)\n",
        "\n",
        "print(\"Baseline predictions on test set:\")\n",
        "print(y_pred_baseline)\n",
        "print(f\"\\n(Notice: every prediction is the same!)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìè Step 5: Evaluating the Baseline\n",
        "\n",
        "Now let's see how well our baseline performs.\n",
        "\n",
        "### Accuracy\n",
        "\n",
        "$$\n",
        "\\text{Accuracy} = \\frac{\\text{Correct Predictions}}{\\text{Total Predictions}}\n",
        "$$\n",
        "\n",
        "**In clinical terms:** Out of 20 test patients, how many did we classify correctly?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate accuracy\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"BASELINE MODEL RESULTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"\\nAccuracy: {baseline_accuracy:.1%}\")\n",
        "print(f\"\\nThis means: out of {len(y_test)} test patients,\")\n",
        "print(f\"we correctly classified {int(baseline_accuracy * len(y_test))} of them.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The Confusion Matrix\n",
        "\n",
        "Accuracy alone can be misleading. Let's look at what the model got right and wrong using a **confusion matrix**.\n",
        "\n",
        "```\n",
        "                    Predicted\n",
        "                 Low Risk | High Risk\n",
        "              +-----------+-----------+\n",
        "    Low Risk  |    TN     |    FP     |   Actual Low Risk\n",
        "Actual        +-----------+-----------+\n",
        "    High Risk |    FN     |    TP     |   Actual High Risk\n",
        "              +-----------+-----------+\n",
        "```\n",
        "\n",
        "- **TN (True Negative):** Correctly predicted Low Risk\n",
        "- **TP (True Positive):** Correctly predicted High Risk  \n",
        "- **FP (False Positive):** Predicted High Risk, but was actually Low Risk\n",
        "- **FN (False Negative):** Predicted Low Risk, but was actually High Risk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred_baseline)\n",
        "\n",
        "# Visualize it\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "\n",
        "sns.heatmap(\n",
        "    cm, \n",
        "    annot=True, \n",
        "    fmt='d', \n",
        "    cmap='Blues',\n",
        "    xticklabels=['Predicted\\nLow Risk', 'Predicted\\nHigh Risk'],\n",
        "    yticklabels=['Actual\\nLow Risk', 'Actual\\nHigh Risk'],\n",
        "    annot_kws={'size': 16, 'fontweight': 'bold'},\n",
        "    cbar_kws={'label': 'Count'},\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "ax.set_title('Confusion Matrix: Baseline Model', fontsize=14, fontweight='bold', pad=20)\n",
        "ax.set_xlabel('')\n",
        "ax.set_ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üí° The Problem with the Baseline\n",
        "\n",
        "Look at the confusion matrix:\n",
        "\n",
        "- The model predicts **Low Risk for everyone**\n",
        "- It gets all the actual Low Risk patients correct (top-left)\n",
        "- But it **misses ALL the High Risk patients** (bottom-left)\n",
        "\n",
        "**Clinical translation:** \n",
        "\n",
        "A model that misses ALL high-risk patients is useless, even if accuracy looks decent!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Let's be explicit about what went wrong\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"Breakdown of predictions:\")\n",
        "print(f\"\\n‚úÖ True Negatives (Low Risk, correctly identified):  {tn}\")\n",
        "print(f\"‚úÖ True Positives (High Risk, correctly identified): {tp}\")\n",
        "print(f\"‚ùå False Positives (Said High Risk, was Low Risk):   {fp}\")\n",
        "print(f\"‚ùå False Negatives (Said Low Risk, was High Risk):   {fn}\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è  The baseline MISSED {fn} out of {fn+tp} High Risk patients!\")\n",
        "print(f\"    That's a {fn/(fn+tp)*100:.0f}% miss rate on the patients we care most about.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ü§î Step 6: Reflection ‚Äî What Does This Mean?\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **Accuracy can be misleading** ‚Äî 70% sounds good, but we missed all high-risk patients\n",
        "\n",
        "2. **The baseline is a benchmark** ‚Äî Any useful model MUST beat this\n",
        "\n",
        "3. **Class imbalance matters** ‚Äî When one class dominates, simple strategies look good\n",
        "\n",
        "4. **Context determines what \"good\" means** ‚Äî In clinical settings, missing high-risk patients (false negatives) is often worse than false alarms (false positives)\n",
        "\n",
        "### Clinical Perspective\n",
        "\n",
        "Imagine if this were a real screening tool:\n",
        "\n",
        "- Saying \"Everyone is Low Risk\" gets you 70% accuracy\n",
        "- But you'd miss every single patient who actually needs intervention\n",
        "- This is why we need to look beyond accuracy\n",
        "\n",
        "### Coming Up Next\n",
        "\n",
        "In the next chapters, we'll:\n",
        "- Learn algorithms that actually USE the features\n",
        "- Look at metrics beyond accuracy (precision, recall, AUC)\n",
        "- See how to tune models for clinical goals\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ Experiments for You\n",
        "\n",
        "Try these modifications to build intuition:\n",
        "\n",
        "### Experiment 1: Change the Class Balance\n",
        "\n",
        "Go back to the data creation cell and change the percentile threshold from 70 to 50:\n",
        "```python\n",
        "df['high_risk'] = (risk_score > np.percentile(risk_score, 50)).astype(int)\n",
        "```\n",
        "What happens to the baseline accuracy?\n",
        "\n",
        "### Experiment 2: Change the Test Size\n",
        "\n",
        "Change `test_size=0.2` to `test_size=0.5`. \n",
        "- Does the accuracy change much?\n",
        "- Is the accuracy more or less stable?\n",
        "\n",
        "### Experiment 3: Random Baseline\n",
        "\n",
        "Change the baseline strategy from `'most_frequent'` to `'uniform'` (random guessing):\n",
        "```python\n",
        "baseline_model = DummyClassifier(strategy='uniform', random_state=42)\n",
        "```\n",
        "What accuracy do you get now?\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Summary\n",
        "\n",
        "| Concept | What It Means |\n",
        "|---------|---------------|\n",
        "| **Features (X)** | The patient data we use to make predictions |\n",
        "| **Target (y)** | What we want to predict |\n",
        "| **Train/Test Split** | Separate data for learning vs. evaluation |\n",
        "| **Baseline** | Simplest possible prediction (benchmark) |\n",
        "| **Accuracy** | Percentage of correct predictions |\n",
        "| **Confusion Matrix** | Breakdown of right/wrong predictions |\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. Always establish a baseline before using complex models\n",
        "2. Accuracy alone doesn't tell the whole story\n",
        "3. The baseline we need to beat is: **predict the most common class**\n",
        "4. Clinical context determines which errors matter more\n",
        "\n",
        "---\n",
        "\n",
        "**Next Chapter:** [Data for Clinical Questions](../02_data_for_clinical_questions/)\n",
        "\n",
        "---\n",
        "\n",
        "*Machine Learning For Dentists: From Torque To Tensors*  \n",
        "*¬© 2024 Francisco Teixeira Barbosa*\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
