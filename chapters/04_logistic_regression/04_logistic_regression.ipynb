{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 04 ‚Äî Logistic Regression: When the Answer is Yes or No\n",
        "\n",
        "> **Book**: Machine Learning For Dentists: From Torque To Tensors\n",
        "\n",
        "---\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this codelab, you will be able to:\n",
        "\n",
        "1. **Explain** how logistic regression transforms a linear score into a probability\n",
        "2. **Train** a logistic regression model using scikit-learn\n",
        "3. **Interpret** weights as odds ratios with clinical meaning\n",
        "4. **Evaluate** classification models using accuracy, precision, recall, F1, and ROC-AUC\n",
        "5. **Choose** appropriate decision thresholds based on clinical costs\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 1: Setup and Data Loading\n",
        "\n",
        "Let's set up our environment with the Periospot brand colors and load the implant success dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix, classification_report,\n",
        "    precision_recall_curve, average_precision_score\n",
        ")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Periospot brand colors\n",
        "PERIOSPOT_COLORS = {\n",
        "    'periospot_blue': '#15365a',\n",
        "    'mystic_blue': '#003049',\n",
        "    'periospot_red': '#6c1410',\n",
        "    'crimson_blaze': '#a92a2a',\n",
        "    'vanilla_cream': '#f7f0da',\n",
        "    'black': '#000000',\n",
        "    'white': '#ffffff'\n",
        "}\n",
        "\n",
        "# Configure matplotlib with brand styling\n",
        "plt.rcParams.update({\n",
        "    'font.family': 'DejaVu Sans',\n",
        "    'font.size': 12,\n",
        "    'axes.titlesize': 16,\n",
        "    'axes.labelsize': 12,\n",
        "    'xtick.labelsize': 10,\n",
        "    'ytick.labelsize': 10,\n",
        "    'figure.facecolor': 'white',\n",
        "    'axes.facecolor': 'white',\n",
        "    'axes.edgecolor': PERIOSPOT_COLORS['periospot_blue'],\n",
        "    'axes.labelcolor': PERIOSPOT_COLORS['mystic_blue'],\n",
        "    'xtick.color': PERIOSPOT_COLORS['mystic_blue'],\n",
        "    'ytick.color': PERIOSPOT_COLORS['mystic_blue'],\n",
        "    'text.color': PERIOSPOT_COLORS['black']\n",
        "})\n",
        "\n",
        "# Create figures directory if it doesn't exist\n",
        "Path('figures').mkdir(exist_ok=True)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(f\"\\nüìä Periospot brand colors loaded: {list(PERIOSPOT_COLORS.keys())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the implant success dataset\n",
        "df = pd.read_csv('data/implant_success_data_training.csv')\n",
        "\n",
        "print(f\"üìä Dataset loaded: {df.shape[0]} implant cases, {df.shape[1]} columns\")\n",
        "print(f\"\\nüéØ Target variable: 'success' (1 = success, 0 = failure)\")\n",
        "print(f\"\\nüìã Columns: {list(df.columns)}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 2: Exploratory Data Analysis\n",
        "\n",
        "Before building our model, let's understand the data ‚Äî especially the **class distribution** (balance between success and failure cases).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "print(\"üìä Dataset Summary Statistics:\\n\")\n",
        "df.describe().round(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution - critical for classification problems!\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Count plot\n",
        "class_counts = df['success'].value_counts()\n",
        "colors = [PERIOSPOT_COLORS['crimson_blaze'], PERIOSPOT_COLORS['periospot_blue']]\n",
        "bars = axes[0].bar(['Failure (0)', 'Success (1)'], \n",
        "                   [class_counts[0], class_counts[1]], \n",
        "                   color=colors, edgecolor='white', linewidth=2)\n",
        "axes[0].set_ylabel('Count')\n",
        "axes[0].set_title('Class Distribution: Success vs Failure')\n",
        "\n",
        "# Add count labels\n",
        "for bar, count in zip(bars, [class_counts[0], class_counts[1]]):\n",
        "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
        "                 f'{count}', ha='center', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Pie chart\n",
        "axes[1].pie([class_counts[0], class_counts[1]], \n",
        "            labels=['Failure', 'Success'],\n",
        "            colors=colors,\n",
        "            autopct='%1.1f%%',\n",
        "            explode=(0.02, 0.02),\n",
        "            startangle=90,\n",
        "            textprops={'fontsize': 12})\n",
        "axes[1].set_title('Class Proportions')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/01_class_distribution.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Class Balance:\")\n",
        "print(f\"   Failures: {class_counts[0]} ({class_counts[0]/len(df)*100:.1f}%)\")\n",
        "print(f\"   Successes: {class_counts[1]} ({class_counts[1]/len(df)*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature distributions by outcome\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "features_to_plot = [\n",
        "    ('insertion_torque_ncm', 'Insertion Torque (Ncm)'),\n",
        "    ('isq_placement', 'ISQ at Placement'),\n",
        "    ('hounsfield_units', 'Bone Density (HU)'),\n",
        "    ('age', 'Patient Age'),\n",
        "    ('implant_length_mm', 'Implant Length (mm)'),\n",
        "    ('implant_diameter_mm', 'Implant Diameter (mm)')\n",
        "]\n",
        "\n",
        "for ax, (feature, label) in zip(axes.flatten(), features_to_plot):\n",
        "    # Separate by outcome\n",
        "    failures = df[df['success'] == 0][feature]\n",
        "    successes = df[df['success'] == 1][feature]\n",
        "    \n",
        "    ax.hist(failures, bins=20, alpha=0.6, color=PERIOSPOT_COLORS['crimson_blaze'],\n",
        "            label=f'Failure (n={len(failures)})', edgecolor='white')\n",
        "    ax.hist(successes, bins=20, alpha=0.6, color=PERIOSPOT_COLORS['periospot_blue'],\n",
        "            label=f'Success (n={len(successes)})', edgecolor='white')\n",
        "    \n",
        "    ax.set_xlabel(label)\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.legend(loc='upper right', fontsize=9)\n",
        "    ax.set_title(f'{label} by Outcome')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/01b_feature_distributions.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 3: Understanding the Sigmoid Function\n",
        "\n",
        "The **sigmoid function** is the heart of logistic regression. It transforms any real number into a probability between 0 and 1.\n",
        "\n",
        "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the sigmoid function\n",
        "def sigmoid(z):\n",
        "    \"\"\"The sigmoid function: squashes any number into [0, 1]\"\"\"\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "# Create z values from -10 to 10\n",
        "z = np.linspace(-10, 10, 200)\n",
        "p = sigmoid(z)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "# Main sigmoid curve\n",
        "ax.plot(z, p, color=PERIOSPOT_COLORS['periospot_blue'], linewidth=3, label='œÉ(z) = 1/(1+e‚Åª·∂ª)')\n",
        "\n",
        "# Reference lines\n",
        "ax.axhline(0.5, color=PERIOSPOT_COLORS['crimson_blaze'], linestyle='--', alpha=0.7, label='p = 0.5 (decision boundary)')\n",
        "ax.axvline(0, color=PERIOSPOT_COLORS['mystic_blue'], linestyle=':', alpha=0.7, label='z = 0')\n",
        "\n",
        "# Shade regions\n",
        "ax.fill_between(z, 0, p, where=(z < 0), alpha=0.2, color=PERIOSPOT_COLORS['crimson_blaze'], label='Predict Failure (p < 0.5)')\n",
        "ax.fill_between(z, 0, p, where=(z >= 0), alpha=0.2, color=PERIOSPOT_COLORS['periospot_blue'], label='Predict Success (p ‚â• 0.5)')\n",
        "\n",
        "# Mark key points\n",
        "key_z = [-5, -2, 0, 2, 5]\n",
        "for z_val in key_z:\n",
        "    p_val = sigmoid(z_val)\n",
        "    ax.plot(z_val, p_val, 'o', color=PERIOSPOT_COLORS['mystic_blue'], markersize=10)\n",
        "    ax.annotate(f'({z_val}, {p_val:.2f})', (z_val, p_val), \n",
        "                textcoords=\"offset points\", xytext=(0, 15), ha='center', fontsize=9)\n",
        "\n",
        "ax.set_xlabel('z (linear score = w¬∑x + b)', fontsize=12)\n",
        "ax.set_ylabel('œÉ(z) = Probability', fontsize=12)\n",
        "ax.set_title('The Sigmoid Function: Transforming Scores to Probabilities', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='upper left', fontsize=10)\n",
        "ax.set_xlim(-10, 10)\n",
        "ax.set_ylim(-0.05, 1.05)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/02_sigmoid_function.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìù Key Properties of the Sigmoid:\")\n",
        "print(\"   ‚Ä¢ Output is always between 0 and 1\")\n",
        "print(\"   ‚Ä¢ When z = 0, œÉ(z) = 0.5 (maximum uncertainty)\")\n",
        "print(\"   ‚Ä¢ Very negative z ‚Üí probability close to 0\")\n",
        "print(\"   ‚Ä¢ Very positive z ‚Üí probability close to 1\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 4: Data Preparation\n",
        "\n",
        "Before training, we need to:\n",
        "1. Select features and target\n",
        "2. Split into train/test sets\n",
        "3. Scale features (important for logistic regression!)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features for the model\n",
        "feature_columns = [\n",
        "    'insertion_torque_ncm',\n",
        "    'isq_placement',\n",
        "    'hounsfield_units',\n",
        "    'age',\n",
        "    'smoking_status',\n",
        "    'diabetes_status',\n",
        "    'implant_length_mm',\n",
        "    'implant_diameter_mm'\n",
        "]\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df['success']\n",
        "\n",
        "print(f\"üìä Features shape: {X.shape}\")\n",
        "print(f\"üéØ Target shape: {y.shape}\")\n",
        "print(f\"\\nüìã Features: {feature_columns}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train-test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"üìä Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"üìä Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"\\n‚úÖ Stratified split ensures class balance is preserved:\")\n",
        "print(f\"   Train success rate: {y_train.mean():.1%}\")\n",
        "print(f\"   Test success rate: {y_test.mean():.1%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame for interpretability\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)\n",
        "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)\n",
        "\n",
        "print(\"‚úÖ Features scaled using StandardScaler\")\n",
        "print(\"\\nüìä Scaled feature statistics (should be mean‚âà0, std‚âà1):\")\n",
        "print(X_train_scaled_df.describe().round(3).loc[['mean', 'std']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 5: Training the Logistic Regression Model\n",
        "\n",
        "Now we train the model using scikit-learn's `LogisticRegression`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train logistic regression model\n",
        "model = LogisticRegression(\n",
        "    penalty='l2',           # L2 regularization (prevents overfitting)\n",
        "    C=1.0,                  # Regularization strength (inverse)\n",
        "    solver='lbfgs',         # Optimization algorithm\n",
        "    max_iter=1000,          # Maximum iterations\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"‚úÖ Model trained successfully!\")\n",
        "print(f\"\\nüìä Model converged in optimization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract and display learned weights\n",
        "weights = model.coef_[0]\n",
        "intercept = model.intercept_[0]\n",
        "\n",
        "print(\"üìä Learned Model Parameters:\\n\")\n",
        "print(f\"{'Feature':<25} {'Weight':>10} {'Odds Ratio':>12}\")\n",
        "print(\"-\" * 50)\n",
        "for feature, weight in zip(feature_columns, weights):\n",
        "    odds_ratio = np.exp(weight)\n",
        "    print(f\"{feature:<25} {weight:>10.4f} {odds_ratio:>12.4f}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Intercept (b)':<25} {intercept:>10.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize odds ratios with confidence context\n",
        "fig, ax = plt.subplots(figsize=(12, 7))\n",
        "\n",
        "# Calculate odds ratios\n",
        "odds_ratios = np.exp(weights)\n",
        "sorted_idx = np.argsort(odds_ratios)\n",
        "\n",
        "# Create horizontal bar chart\n",
        "y_pos = np.arange(len(feature_columns))\n",
        "colors = [PERIOSPOT_COLORS['crimson_blaze'] if odds_ratios[i] < 1 \n",
        "          else PERIOSPOT_COLORS['periospot_blue'] for i in sorted_idx]\n",
        "\n",
        "bars = ax.barh(y_pos, odds_ratios[sorted_idx], color=colors, edgecolor='white', linewidth=2)\n",
        "ax.set_yticks(y_pos)\n",
        "ax.set_yticklabels([feature_columns[i] for i in sorted_idx])\n",
        "ax.axvline(1.0, color=PERIOSPOT_COLORS['mystic_blue'], linestyle='--', linewidth=2, label='OR = 1 (no effect)')\n",
        "\n",
        "# Add value labels\n",
        "for bar, idx in zip(bars, sorted_idx):\n",
        "    width = bar.get_width()\n",
        "    x_pos = width + 0.02 if width > 1 else width - 0.1\n",
        "    ax.text(x_pos, bar.get_y() + bar.get_height()/2,\n",
        "            f'{odds_ratios[idx]:.3f}', va='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "ax.set_xlabel('Odds Ratio', fontsize=12)\n",
        "ax.set_title('Feature Importance: Odds Ratios\\n(OR > 1 increases success odds, OR < 1 decreases)', \n",
        "             fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='upper right')\n",
        "\n",
        "# Add interpretation text\n",
        "ax.text(0.02, 0.98, 'Red = Decreases success odds\\nBlue = Increases success odds',\n",
        "        transform=ax.transAxes, fontsize=10, verticalalignment='top',\n",
        "        bbox=dict(boxstyle='round', facecolor=PERIOSPOT_COLORS['vanilla_cream'], alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/03_odds_ratios.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 6: Model Evaluation\n",
        "\n",
        "For classification, we use different metrics than regression:\n",
        "- **Accuracy**: % of correct predictions\n",
        "- **Precision**: Of predicted successes, how many were actual successes?\n",
        "- **Recall (Sensitivity)**: Of actual successes, how many did we catch?\n",
        "- **F1 Score**: Harmonic mean of precision and recall\n",
        "- **ROC-AUC**: Area under the ROC curve (model's discrimination ability)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "y_pred_train = model.predict(X_train_scaled)\n",
        "y_pred_test = model.predict(X_test_scaled)\n",
        "\n",
        "# Predicted probabilities (for ROC curve)\n",
        "y_prob_train = model.predict_proba(X_train_scaled)[:, 1]\n",
        "y_prob_test = model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "print(\"‚úÖ Predictions made!\")\n",
        "print(f\"\\nüìä Sample predictions (first 10 test cases):\")\n",
        "sample_results = pd.DataFrame({\n",
        "    'Actual': y_test.values[:10],\n",
        "    'Predicted': y_pred_test[:10],\n",
        "    'Probability': y_prob_test[:10].round(3)\n",
        "})\n",
        "print(sample_results.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate all metrics\n",
        "metrics = {\n",
        "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC'],\n",
        "    'Training': [\n",
        "        accuracy_score(y_train, y_pred_train),\n",
        "        precision_score(y_train, y_pred_train),\n",
        "        recall_score(y_train, y_pred_train),\n",
        "        f1_score(y_train, y_pred_train),\n",
        "        roc_auc_score(y_train, y_prob_train)\n",
        "    ],\n",
        "    'Test': [\n",
        "        accuracy_score(y_test, y_pred_test),\n",
        "        precision_score(y_test, y_pred_test),\n",
        "        recall_score(y_test, y_pred_test),\n",
        "        f1_score(y_test, y_pred_test),\n",
        "        roc_auc_score(y_test, y_prob_test)\n",
        "    ]\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics)\n",
        "metrics_df['Training'] = metrics_df['Training'].round(4)\n",
        "metrics_df['Test'] = metrics_df['Test'].round(4)\n",
        "\n",
        "print(\"üìä Model Performance Metrics:\\n\")\n",
        "print(metrics_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ROC Curve\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# ROC Curve\n",
        "fpr_train, tpr_train, _ = roc_curve(y_train, y_prob_train)\n",
        "fpr_test, tpr_test, _ = roc_curve(y_test, y_prob_test)\n",
        "\n",
        "auc_train = roc_auc_score(y_train, y_prob_train)\n",
        "auc_test = roc_auc_score(y_test, y_prob_test)\n",
        "\n",
        "axes[0].plot(fpr_train, tpr_train, color=PERIOSPOT_COLORS['mystic_blue'], \n",
        "             linewidth=2, label=f'Training (AUC = {auc_train:.3f})')\n",
        "axes[0].plot(fpr_test, tpr_test, color=PERIOSPOT_COLORS['crimson_blaze'], \n",
        "             linewidth=2, label=f'Test (AUC = {auc_test:.3f})')\n",
        "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
        "\n",
        "axes[0].fill_between(fpr_test, 0, tpr_test, alpha=0.2, color=PERIOSPOT_COLORS['crimson_blaze'])\n",
        "axes[0].set_xlabel('False Positive Rate (1 - Specificity)')\n",
        "axes[0].set_ylabel('True Positive Rate (Sensitivity)')\n",
        "axes[0].set_title('ROC Curve: Model Discrimination', fontweight='bold')\n",
        "axes[0].legend(loc='lower right')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_prob_test)\n",
        "ap = average_precision_score(y_test, y_prob_test)\n",
        "\n",
        "axes[1].plot(recall_curve, precision_curve, color=PERIOSPOT_COLORS['periospot_blue'], \n",
        "             linewidth=2, label=f'PR Curve (AP = {ap:.3f})')\n",
        "axes[1].axhline(y_test.mean(), color=PERIOSPOT_COLORS['crimson_blaze'], \n",
        "                linestyle='--', label=f'Baseline (prevalence = {y_test.mean():.2f})')\n",
        "axes[1].fill_between(recall_curve, 0, precision_curve, alpha=0.2, color=PERIOSPOT_COLORS['periospot_blue'])\n",
        "axes[1].set_xlabel('Recall (Sensitivity)')\n",
        "axes[1].set_ylabel('Precision')\n",
        "axes[1].set_title('Precision-Recall Curve', fontweight='bold')\n",
        "axes[1].legend(loc='lower left')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/04_roc_curve.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä AUC Interpretation:\")\n",
        "print(f\"   ‚Ä¢ AUC = 0.5: Random guessing\")\n",
        "print(f\"   ‚Ä¢ AUC = 0.7-0.8: Acceptable discrimination\")\n",
        "print(f\"   ‚Ä¢ AUC = 0.8-0.9: Excellent discrimination\")\n",
        "print(f\"   ‚Ä¢ AUC > 0.9: Outstanding discrimination\")\n",
        "print(f\"\\n   Our model: AUC = {auc_test:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 7: Threshold Analysis\n",
        "\n",
        "By default, we classify as \"success\" when P(success) > 0.5. But this threshold can be adjusted based on clinical costs!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze different thresholds\n",
        "thresholds = np.arange(0.1, 0.95, 0.05)\n",
        "\n",
        "threshold_metrics = []\n",
        "for thresh in thresholds:\n",
        "    y_pred_thresh = (y_prob_test >= thresh).astype(int)\n",
        "    threshold_metrics.append({\n",
        "        'Threshold': thresh,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred_thresh),\n",
        "        'Precision': precision_score(y_test, y_pred_thresh, zero_division=0),\n",
        "        'Recall': recall_score(y_test, y_pred_thresh, zero_division=0),\n",
        "        'F1': f1_score(y_test, y_pred_thresh, zero_division=0)\n",
        "    })\n",
        "\n",
        "threshold_df = pd.DataFrame(threshold_metrics)\n",
        "\n",
        "# Plot threshold analysis\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Metrics vs Threshold\n",
        "axes[0].plot(threshold_df['Threshold'], threshold_df['Accuracy'], \n",
        "             label='Accuracy', linewidth=2, color=PERIOSPOT_COLORS['periospot_blue'])\n",
        "axes[0].plot(threshold_df['Threshold'], threshold_df['Precision'], \n",
        "             label='Precision', linewidth=2, color=PERIOSPOT_COLORS['crimson_blaze'])\n",
        "axes[0].plot(threshold_df['Threshold'], threshold_df['Recall'], \n",
        "             label='Recall', linewidth=2, color=PERIOSPOT_COLORS['mystic_blue'])\n",
        "axes[0].plot(threshold_df['Threshold'], threshold_df['F1'], \n",
        "             label='F1 Score', linewidth=2, linestyle='--', color='black')\n",
        "\n",
        "axes[0].axvline(0.5, color='gray', linestyle=':', alpha=0.7, label='Default threshold (0.5)')\n",
        "axes[0].set_xlabel('Classification Threshold')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('Metrics vs. Threshold', fontweight='bold')\n",
        "axes[0].legend(loc='lower center')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].set_xlim(0.1, 0.9)\n",
        "\n",
        "# Precision-Recall Tradeoff\n",
        "axes[1].plot(threshold_df['Recall'], threshold_df['Precision'], \n",
        "             'o-', color=PERIOSPOT_COLORS['periospot_blue'], linewidth=2, markersize=6)\n",
        "\n",
        "# Mark specific thresholds\n",
        "for thresh in [0.3, 0.5, 0.7]:\n",
        "    row = threshold_df[threshold_df['Threshold'].round(2) == thresh].iloc[0]\n",
        "    color = 'green' if thresh == 0.5 else PERIOSPOT_COLORS['crimson_blaze']\n",
        "    axes[1].annotate(f't={thresh}', (row['Recall'], row['Precision']),\n",
        "                     textcoords=\"offset points\", xytext=(10, 5), fontsize=10, color=color)\n",
        "\n",
        "axes[1].set_xlabel('Recall (Sensitivity)')\n",
        "axes[1].set_ylabel('Precision')\n",
        "axes[1].set_title('Precision-Recall Tradeoff at Different Thresholds', fontweight='bold')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/05_threshold_analysis.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion matrices at different thresholds\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "thresholds_to_show = [0.3, 0.5, 0.7]\n",
        "titles = ['Conservative (t=0.3)\\nFavor catching successes', \n",
        "          'Default (t=0.5)\\nBalanced', \n",
        "          'Strict (t=0.7)\\nFavor confidence']\n",
        "\n",
        "for ax, thresh, title in zip(axes, thresholds_to_show, titles):\n",
        "    y_pred_thresh = (y_prob_test >= thresh).astype(int)\n",
        "    cm = confusion_matrix(y_test, y_pred_thresh)\n",
        "    \n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
        "                xticklabels=['Pred Failure', 'Pred Success'],\n",
        "                yticklabels=['Actual Failure', 'Actual Success'],\n",
        "                annot_kws={'size': 14})\n",
        "    ax.set_title(title, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/06_confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 8: Making a Prediction (Dr. Marco's Patient)\n",
        "\n",
        "Let's use our trained model to predict the success probability for Dr. Marco's patient from the chapter scenario.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dr. Marco's patient data\n",
        "marcos_patient = pd.DataFrame([{\n",
        "    'insertion_torque_ncm': 32,\n",
        "    'isq_placement': 68,\n",
        "    'hounsfield_units': 650,  # Reasonable bone density\n",
        "    'age': 45,\n",
        "    'smoking_status': 0,      # Non-smoker\n",
        "    'diabetes_status': 0,     # No diabetes\n",
        "    'implant_length_mm': 10,\n",
        "    'implant_diameter_mm': 4.0\n",
        "}])\n",
        "\n",
        "# Scale the features\n",
        "marcos_patient_scaled = scaler.transform(marcos_patient)\n",
        "\n",
        "# Make prediction\n",
        "prob_success = model.predict_proba(marcos_patient_scaled)[0, 1]\n",
        "prediction = 'Success' if prob_success >= 0.5 else 'Failure'\n",
        "\n",
        "print(\"ü¶∑ Dr. Marco's Patient Prediction\\n\")\n",
        "print(\"Patient Features:\")\n",
        "for col in marcos_patient.columns:\n",
        "    print(f\"   {col}: {marcos_patient[col].values[0]}\")\n",
        "\n",
        "print(f\"\\nüìä Model Prediction:\")\n",
        "print(f\"   Probability of Success: {prob_success:.1%}\")\n",
        "print(f\"   Classification (at 0.5 threshold): {prediction}\")\n",
        "\n",
        "print(f\"\\nüí° Clinical Interpretation:\")\n",
        "if prob_success >= 0.7:\n",
        "    print(\"   ‚Üí High confidence in success. Immediate loading reasonable.\")\n",
        "elif prob_success >= 0.5:\n",
        "    print(\"   ‚Üí Borderline case. Consider patient factors and preferences.\")\n",
        "else:\n",
        "    print(\"   ‚Üí Lower confidence. Consider waiting or additional assessment.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Phase 9: Summary and Key Takeaways\n",
        "\n",
        "Let's summarize what we learned in this codelab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final summary\n",
        "print(\"=\"*60)\n",
        "print(\"üìö LOGISTIC REGRESSION CODELAB SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nüìä Dataset:\")\n",
        "print(f\"   ‚Ä¢ {len(df)} implant cases\")\n",
        "print(f\"   ‚Ä¢ Success rate: {df['success'].mean():.1%}\")\n",
        "print(f\"   ‚Ä¢ {len(feature_columns)} features used\")\n",
        "\n",
        "print(\"\\nüéØ Model Performance (Test Set):\")\n",
        "print(f\"   ‚Ä¢ Accuracy: {accuracy_score(y_test, y_pred_test):.1%}\")\n",
        "print(f\"   ‚Ä¢ ROC-AUC: {roc_auc_score(y_test, y_prob_test):.3f}\")\n",
        "print(f\"   ‚Ä¢ F1 Score: {f1_score(y_test, y_pred_test):.3f}\")\n",
        "\n",
        "print(\"\\nüîë Top 3 Predictors (by |weight|):\")\n",
        "weight_importance = sorted(zip(feature_columns, np.abs(weights)), key=lambda x: x[1], reverse=True)\n",
        "for feature, importance in weight_importance[:3]:\n",
        "    idx = feature_columns.index(feature)\n",
        "    direction = \"‚Üë success\" if weights[idx] > 0 else \"‚Üì success\"\n",
        "    print(f\"   ‚Ä¢ {feature}: OR = {np.exp(weights[idx]):.3f} ({direction})\")\n",
        "\n",
        "print(\"\\nüí° Key Learnings:\")\n",
        "print(\"   1. Sigmoid transforms linear scores into probabilities\")\n",
        "print(\"   2. Weights ‚Üí Odds Ratios for clinical interpretation\")\n",
        "print(\"   3. Threshold choice depends on clinical costs\")\n",
        "print(\"   4. ROC-AUC measures discrimination ability\")\n",
        "print(\"   5. Class imbalance requires careful evaluation\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List generated figures\n",
        "import os\n",
        "\n",
        "print(\"üìÅ Generated Figures:\")\n",
        "for f in sorted(os.listdir('figures')):\n",
        "    if f.endswith('.png'):\n",
        "        print(f\"   ‚Ä¢ figures/{f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üßò Reflection Log\n",
        "\n",
        "### What did you learn in this session?\n",
        "- How logistic regression transforms linear scores into probabilities using the sigmoid function\n",
        "- How to interpret model weights as odds ratios for clinical meaning\n",
        "- The importance of choosing appropriate thresholds based on clinical costs\n",
        "- How to evaluate classification models using multiple metrics (accuracy, precision, recall, F1, ROC-AUC)\n",
        "\n",
        "### How will this improve Periospot AI?\n",
        "- Provides a foundation for binary classification tasks (success/failure, disease/healthy)\n",
        "- Enables probabilistic predictions that inform clinical decision-making\n",
        "- Demonstrates interpretable ML that clinicians can trust and explain\n",
        "\n",
        "---\n",
        "\n",
        "*Questions or feedback? Open an issue on the book's GitHub repository or reach out on Twitter @cisco_research*\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
